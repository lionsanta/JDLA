[JDLA認定プログラム](http://study-ai.com/jdla)で、JDLA E資格に準拠した学習を行った。

![Image](http://ai999.careers/bnr_jdla.png)

オライリー本で学習した内容との重複は省く。


# Google Colabの使い方

・np.randomのヘルプを参照したい時、コードセルに以下を入力して実行する。
　> np.random? 

・runtimeの変更（host/local）も可能
・runtime typeの変更でGPU/TPUの選択が可能
・Googleドライブのマウント

　> from google.colab import drive
　> drive.mount("/content/drive")

# 機械学習とは

・機械学習に適した課題であるか、判断すること。
　・他部署が運用する場合、そのチームが機械学習の知識が必要。
　・ルールベースよりもテストがしづらい。モデル更新により入力出力が変わる。

・機械学習の定義
　コンピュータプログラムが行うタスクTを性能指標Pで測定し、経験Eで
　改善させること。
　人がプログラムするのは、学習（経験Eでの改善方法、性能指標P、タスクT）。

# 線形回帰モデル

・入力（説明変数）から出力（目的変数）を予測する。

・慣例として、予測値にはハット^をつける。（正解データと区別）
　・データは、回帰直線に誤差が加わり観測されていると仮定する。
　・単回帰：説明変数が１つ、重回帰：説明変数が複数（多次元）

# 非線形回帰モデル

・基底展開法
　・回帰関数として、非線形関数（基底関数）とパラメータベクトルの線形結合を使用
　・未知のパラメータは（線形回帰と同様）最小二乗法や最尤法で推定する。

# 正則化法

　・基底関数の数が多くなるなどモデルが複雑化すると過学習しやすくなる。
　・正則化法とは、正則化項（罰則項）を使って複雑化を防ぐこと。

　・パラメータに制約を与えて、その範囲内でMSEが最小になる点を
　　探すこと。
　　・L2ノルムを利用：Ridge推定量（縮小推定）
　　　パラメータの原点付近の円の中でMSEが最小になる点を求める。
　　・L1ノルムを利用：Lasso推定量（スペース推定）
　　　パラメータのダイヤモンド形（パラメータが２つで二次の場合
　　　正方形）の中でMSEが最小になる点を求める。
　　　・ダイヤモンドの角では、パラメータが0になる。
　　　　→Deep Learningで説明変数や基底関数を減らすのに利用する。

　・正則化（平滑化）パラメータγを極端に大きくすると
　　「Ridge推定量と最小二乗推定量が同じになる」。

# モデル選択

　・ホールドアウト法
　　△：学習用データ、検証用データとデータ量が必要。
　　△：外れ値がどこかに偏ることがある。

　・交差検証法
　　・イテレータごとに学習用データと検証用データを入れ替える。
　　　

　・ホールドアウト法に比べ、交差検証法の汎化性能は低く見える
　　ことがあるが、交差検証法のほうが正確である。

# ロジスティク回帰モデル

　・回帰ではなく分類の為のモデル
　
　・シグモイド関数：微分をシグモイド関数自身で表現できる。
　　最適化問題（MSEや尤度を最大・最小にする点を求める）為に
　　微分を利用する。その際に計算が便利なのでシグモイド関数
　　を利用する。

# 最尤推定

　・ベルヌーイ分布（２項）を利用する。

　・同時確率：あるデータが同時に得られる確率
　　　　　　　（独立である確率の掛け算）
　
　・尤度関数：シグモイド関数のパラメータwにのみ依存する関数
　　・wに関する最適化問題を解く。wの掛け算の微分は面倒なので
　　　対数logをとって、その微分計算を楽にすることが多い。
　　・尤度関数と対数尤度関数の最大値は一致することは証明済。
　　・勾配降下法で計算する。

# 勾配降下法

　・データが巨大な場合、すべてのデータをオンメモリに載せる
　　のは非現実的。確率的勾配降下法を利用する。

　・確率的勾配降下法（SGD）
　　・山が複数ある場合は必ずしも最大値に到達しないが、
　　　ロジスティク回帰モデルについては山はひとつなので問題ない。

# モデルの評価

　・True/False Positivie/Negative
　
　・正解率　True Positive + True Negative / 全データ
　　△：データの偏りによっては指標として不適切。
　　　　スパムメールの判定
　
　・再現率（Recall）　True Positive / 全Positive
　　・Flase Positiveが多くても、抜け漏れを減らしたい時に
　　　使う。例えば、病気の検診。
　
　・適合率（Precision）
　　・True Positive / True Positive + False Positive
　　・見逃し（Flase Positive）が多くても正確さを求める
　　　時に使う。例えばスパムメールの判定。

　・F値
　　・タスクがわからない場合、再現率と適合率の調和平均

# ロジスティック回帰　ハンズオン

・ソースコードの転記になってしまうので割愛。

#  主成分分析　ハンズオン

・ソースコードの転記になってしまうので割愛。

#  k-means

・kの値（クラスタの数）や初期値によってクラスタリング結果が変わる。
　ランダムに与えるのではなくk-means++で初期値を決める。
